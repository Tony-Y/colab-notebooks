{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch-Warmup-FusedAdam.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bb35ce581bbc4101bb70e58e7c12232e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_47a1d76deaa74a019f8d1c81042ba9c8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c9f52e23f2d549b18f85335629926c8c",
              "IPY_MODEL_4d36030f440c4d729d5b0973d197d924"
            ]
          }
        },
        "47a1d76deaa74a019f8d1c81042ba9c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c9f52e23f2d549b18f85335629926c8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_50e86a6e8b0e43bc8585c360256fbfd1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dfdb114eb4af4240b55babd2ad4707a9"
          }
        },
        "4d36030f440c4d729d5b0973d197d924": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_faf3241f622b466e951d58ba0c33419b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 561758208/? [00:50&lt;00:00, 14618757.04it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b1a3268871cb4fc4901e41435b8f079c"
          }
        },
        "50e86a6e8b0e43bc8585c360256fbfd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dfdb114eb4af4240b55babd2ad4707a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "faf3241f622b466e951d58ba0c33419b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b1a3268871cb4fc4901e41435b8f079c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tony-Y/colab-notebooks/blob/master/PyTorch_Warmup_FusedAdam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yO12PYpLWNT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "490bcf43-50a5-4dc8-928a-6bb2aea6241c"
      },
      "source": [
        "!git clone https://github.com/NVIDIA/apex\n",
        "!pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex\n",
        "!rm -r apex"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'apex'...\n",
            "remote: Enumerating objects: 38, done.\u001b[K\n",
            "remote: Counting objects: 100% (38/38), done.\u001b[K\n",
            "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
            "remote: Total 7293 (delta 20), reused 19 (delta 6), pack-reused 7255\u001b[K\n",
            "Receiving objects: 100% (7293/7293), 13.87 MiB | 7.49 MiB/s, done.\n",
            "Resolving deltas: 100% (4919/4919), done.\n",
            "/usr/local/lib/python3.6/dist-packages/pip/_internal/commands/install.py:283: UserWarning: Disabling all use of wheels due to the use of --build-options / --global-options / --install-options.\n",
            "  cmdoptions.check_install_build_global(options)\n",
            "Created temporary directory: /tmp/pip-ephem-wheel-cache-b3tglz3u\n",
            "Created temporary directory: /tmp/pip-req-tracker-h6cc4w5p\n",
            "Created requirements tracker '/tmp/pip-req-tracker-h6cc4w5p'\n",
            "Created temporary directory: /tmp/pip-install-qr571oup\n",
            "Processing ./apex\n",
            "  Created temporary directory: /tmp/pip-req-build-5ftpm7bw\n",
            "  Added file:///content/apex to build tracker '/tmp/pip-req-tracker-h6cc4w5p'\n",
            "    Running setup.py (path:/tmp/pip-req-build-5ftpm7bw/setup.py) egg_info for package from file:///content/apex\n",
            "    Running command python setup.py egg_info\n",
            "\n",
            "\n",
            "    torch.__version__  = 1.5.1+cu101\n",
            "\n",
            "\n",
            "    running egg_info\n",
            "    creating /tmp/pip-req-build-5ftpm7bw/pip-egg-info/apex.egg-info\n",
            "    writing /tmp/pip-req-build-5ftpm7bw/pip-egg-info/apex.egg-info/PKG-INFO\n",
            "    writing dependency_links to /tmp/pip-req-build-5ftpm7bw/pip-egg-info/apex.egg-info/dependency_links.txt\n",
            "    writing top-level names to /tmp/pip-req-build-5ftpm7bw/pip-egg-info/apex.egg-info/top_level.txt\n",
            "    writing manifest file '/tmp/pip-req-build-5ftpm7bw/pip-egg-info/apex.egg-info/SOURCES.txt'\n",
            "    writing manifest file '/tmp/pip-req-build-5ftpm7bw/pip-egg-info/apex.egg-info/SOURCES.txt'\n",
            "    /tmp/pip-req-build-5ftpm7bw/setup.py:51: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "  Source in /tmp/pip-req-build-5ftpm7bw has version 0.1, which satisfies requirement apex==0.1 from file:///content/apex\n",
            "  Removed apex==0.1 from file:///content/apex from build tracker '/tmp/pip-req-tracker-h6cc4w5p'\n",
            "Skipping wheel build for apex, due to binaries being disabled for it.\n",
            "Installing collected packages: apex\n",
            "  Created temporary directory: /tmp/pip-record-1quyzi5v\n",
            "    Running command /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-5ftpm7bw/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-5ftpm7bw/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' --cpp_ext --cuda_ext install --record /tmp/pip-record-1quyzi5v/install-record.txt --single-version-externally-managed --compile\n",
            "\n",
            "\n",
            "    torch.__version__  = 1.5.1+cu101\n",
            "\n",
            "\n",
            "    /tmp/pip-req-build-5ftpm7bw/setup.py:51: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "\n",
            "    Compiling cuda extensions with\n",
            "    nvcc: NVIDIA (R) Cuda compiler driver\n",
            "    Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "    Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "    Cuda compilation tools, release 10.1, V10.1.243\n",
            "    from /usr/local/cuda/bin\n",
            "\n",
            "    running install\n",
            "    running build\n",
            "    running build_py\n",
            "    creating build\n",
            "    creating build/lib.linux-x86_64-3.6\n",
            "    creating build/lib.linux-x86_64-3.6/apex\n",
            "    copying apex/__init__.py -> build/lib.linux-x86_64-3.6/apex\n",
            "    creating build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
            "    copying apex/multi_tensor_apply/__init__.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
            "    copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
            "    creating build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/scaler.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/amp.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/_process_optimizer.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/_amp_state.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/wrap.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/frontend.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/utils.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/__version__.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/rnn_compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/opt.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/handle.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/_initialize.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    creating build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/fused_adagrad.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/fused_novograd.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/__init__.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    creating build/lib.linux-x86_64-3.6/apex/reparameterization\n",
            "    copying apex/reparameterization/__init__.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
            "    copying apex/reparameterization/reparameterization.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
            "    copying apex/reparameterization/weight_norm.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib\n",
            "    copying apex/contrib/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib\n",
            "    creating build/lib.linux-x86_64-3.6/apex/pyprof\n",
            "    copying apex/pyprof/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof\n",
            "    creating build/lib.linux-x86_64-3.6/apex/normalization\n",
            "    copying apex/normalization/__init__.py -> build/lib.linux-x86_64-3.6/apex/normalization\n",
            "    copying apex/normalization/fused_layer_norm.py -> build/lib.linux-x86_64-3.6/apex/normalization\n",
            "    creating build/lib.linux-x86_64-3.6/apex/mlp\n",
            "    copying apex/mlp/__init__.py -> build/lib.linux-x86_64-3.6/apex/mlp\n",
            "    copying apex/mlp/mlp.py -> build/lib.linux-x86_64-3.6/apex/mlp\n",
            "    creating build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "    copying apex/fp16_utils/fp16util.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "    copying apex/fp16_utils/__init__.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "    copying apex/fp16_utils/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "    copying apex/fp16_utils/loss_scaler.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "    creating build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/__init__.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/LARC.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/multiproc.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/optimized_sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/distributed.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    creating build/lib.linux-x86_64-3.6/apex/RNN\n",
            "    copying apex/RNN/cells.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
            "    copying apex/RNN/__init__.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
            "    copying apex/RNN/models.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
            "    copying apex/RNN/RNNBackend.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
            "    creating build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "    copying apex/amp/lists/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "    copying apex/amp/lists/functional_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "    copying apex/amp/lists/torch_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "    copying apex/amp/lists/tensor_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/distributed_fused_adam.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/distributed_fused_lamb.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/distributed_fused_adam_v3.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/distributed_fused_adam_v2.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n",
            "    copying apex/contrib/xentropy/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n",
            "    copying apex/contrib/xentropy/softmax_xentropy.py -> build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n",
            "    copying apex/contrib/sparsity/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n",
            "    copying apex/contrib/sparsity/sparse_masklib.py -> build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n",
            "    copying apex/contrib/sparsity/asp.py -> build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n",
            "    copying apex/contrib/groupbn/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n",
            "    copying apex/contrib/groupbn/batch_norm.py -> build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/self_multihead_attn.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    creating build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n",
            "    copying apex/pyprof/nvtx/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n",
            "    copying apex/pyprof/nvtx/nvmarker.py -> build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n",
            "    creating build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/db.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/parse.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/__main__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/nvvp.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/kernel.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    creating build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/index_slice_join_mutate.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/loss.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/randomSample.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/recurrentCell.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/prof.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/output.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/reduction.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/__main__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/data.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/normalization.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/linear.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/dropout.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/embedding.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/pointwise.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/base.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/misc.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/blas.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/convert.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/usage.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/softmax.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/optim.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/activation.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/utility.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/pooling.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/conv.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    running build_ext\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/utils/cpp_extension.py:305: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "      warnings.warn(msg.format('we could not find ninja.'))\n",
            "    building 'apex_C' extension\n",
            "    creating build/temp.linux-x86_64-3.6\n",
            "    creating build/temp.linux-x86_64-3.6/csrc\n",
            "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c csrc/flatten_unflatten.cpp -o build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=apex_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "    In file included from csrc/flatten_unflatten.cpp:2:0:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/utils/tensor_flatten.h: In member function â€˜at::DeprecatedTypeProperties& torch::utils::TensorGroup::type()â€™:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/utils/tensor_flatten.h:36:28: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "         return tensors[0].type();\n",
            "                                ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/flatten_unflatten.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so\n",
            "    building 'amp_C' extension\n",
            "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/amp_C_frontend.cpp -o build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_sgd_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_sgd_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_scale_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_axpby_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_l2norm_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb_stage_1.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_1.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb_stage_2.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_2.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_adam.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adam.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_adagrad.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adagrad.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_novograd.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_novograd.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_sgd_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_1.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_2.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adam.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adagrad.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_novograd.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so\n",
            "    building 'syncbn' extension\n",
            "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/syncbn.cpp -o build/temp.linux-x86_64-3.6/csrc/syncbn.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/welford.cu -o build/temp.linux-x86_64-3.6/csrc/welford.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/syncbn.o build/temp.linux-x86_64-3.6/csrc/welford.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so\n",
            "    building 'fused_layer_norm_cuda' extension\n",
            "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/layer_norm_cuda.cpp -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp: In function â€˜std::vector<at::Tensor> layer_norm(at::Tensor, c10::IntArrayRef, double)â€™:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro â€˜C10_UNLIKELYâ€™\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro â€˜C10_UNLIKELY_OR_CONSTâ€™\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro â€˜TORCH_CHECK_WITHâ€™\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro â€˜TORCH_CHECKâ€™\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro â€˜CHECK_CUDAâ€™\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:129:3: note: in expansion of macro â€˜CHECK_INPUTâ€™\n",
            "       CHECK_INPUT(input);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp: In function â€˜std::vector<at::Tensor> layer_norm_affine(at::Tensor, c10::IntArrayRef, at::Tensor, at::Tensor, double)â€™:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro â€˜C10_UNLIKELYâ€™\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro â€˜C10_UNLIKELY_OR_CONSTâ€™\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro â€˜TORCH_CHECK_WITHâ€™\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro â€˜TORCH_CHECKâ€™\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro â€˜CHECK_CUDAâ€™\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:149:3: note: in expansion of macro â€˜CHECK_INPUTâ€™\n",
            "       CHECK_INPUT(input);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro â€˜C10_UNLIKELYâ€™\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro â€˜C10_UNLIKELY_OR_CONSTâ€™\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro â€˜TORCH_CHECK_WITHâ€™\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro â€˜TORCH_CHECKâ€™\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro â€˜CHECK_CUDAâ€™\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:150:3: note: in expansion of macro â€˜CHECK_INPUTâ€™\n",
            "       CHECK_INPUT(gamma);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro â€˜C10_UNLIKELYâ€™\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro â€˜C10_UNLIKELY_OR_CONSTâ€™\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro â€˜TORCH_CHECK_WITHâ€™\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro â€˜TORCH_CHECKâ€™\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro â€˜CHECK_CUDAâ€™\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:151:3: note: in expansion of macro â€˜CHECK_INPUTâ€™\n",
            "       CHECK_INPUT(beta);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp: In function â€˜at::Tensor layer_norm_gradient(at::Tensor, at::Tensor, at::Tensor, at::Tensor, c10::IntArrayRef, double)â€™:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro â€˜C10_UNLIKELYâ€™\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro â€˜C10_UNLIKELY_OR_CONSTâ€™\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro â€˜TORCH_CHECK_WITHâ€™\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro â€˜TORCH_CHECKâ€™\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro â€˜CHECK_CUDAâ€™\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:193:3: note: in expansion of macro â€˜CHECK_INPUTâ€™\n",
            "       CHECK_INPUT(dout);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro â€˜C10_UNLIKELYâ€™\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro â€˜C10_UNLIKELY_OR_CONSTâ€™\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro â€˜TORCH_CHECK_WITHâ€™\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro â€˜TORCH_CHECKâ€™\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro â€˜CHECK_CUDAâ€™\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:194:3: note: in expansion of macro â€˜CHECK_INPUTâ€™\n",
            "       CHECK_INPUT(mean);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro â€˜C10_UNLIKELYâ€™\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro â€˜C10_UNLIKELY_OR_CONSTâ€™\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro â€˜TORCH_CHECK_WITHâ€™\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro â€˜TORCH_CHECKâ€™\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro â€˜CHECK_CUDAâ€™\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:195:3: note: in expansion of macro â€˜CHECK_INPUTâ€™\n",
            "       CHECK_INPUT(invvar);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro â€˜C10_UNLIKELYâ€™\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro â€˜C10_UNLIKELY_OR_CONSTâ€™\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro â€˜TORCH_CHECK_WITHâ€™\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro â€˜TORCH_CHECKâ€™\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro â€˜CHECK_CUDAâ€™\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:196:3: note: in expansion of macro â€˜CHECK_INPUTâ€™\n",
            "       CHECK_INPUT(input);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp: In function â€˜std::vector<at::Tensor> layer_norm_gradient_affine(at::Tensor, at::Tensor, at::Tensor, at::Tensor, c10::IntArrayRef, at::Tensor, at::Tensor, double)â€™:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro â€˜C10_UNLIKELYâ€™\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro â€˜C10_UNLIKELY_OR_CONSTâ€™\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro â€˜TORCH_CHECK_WITHâ€™\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro â€˜TORCH_CHECKâ€™\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro â€˜CHECK_CUDAâ€™\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:218:3: note: in expansion of macro â€˜CHECK_INPUTâ€™\n",
            "       CHECK_INPUT(dout);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro â€˜C10_UNLIKELYâ€™\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro â€˜C10_UNLIKELY_OR_CONSTâ€™\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro â€˜TORCH_CHECK_WITHâ€™\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro â€˜TORCH_CHECKâ€™\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro â€˜CHECK_CUDAâ€™\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:219:3: note: in expansion of macro â€˜CHECK_INPUTâ€™\n",
            "       CHECK_INPUT(mean);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro â€˜C10_UNLIKELYâ€™\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro â€˜C10_UNLIKELY_OR_CONSTâ€™\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro â€˜TORCH_CHECK_WITHâ€™\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro â€˜TORCH_CHECKâ€™\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro â€˜CHECK_CUDAâ€™\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:220:3: note: in expansion of macro â€˜CHECK_INPUTâ€™\n",
            "       CHECK_INPUT(invvar);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro â€˜C10_UNLIKELYâ€™\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro â€˜C10_UNLIKELY_OR_CONSTâ€™\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro â€˜TORCH_CHECK_WITHâ€™\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro â€˜TORCH_CHECKâ€™\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro â€˜CHECK_CUDAâ€™\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:221:3: note: in expansion of macro â€˜CHECK_INPUTâ€™\n",
            "       CHECK_INPUT(input);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro â€˜C10_UNLIKELYâ€™\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro â€˜C10_UNLIKELY_OR_CONSTâ€™\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro â€˜TORCH_CHECK_WITHâ€™\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro â€˜TORCH_CHECKâ€™\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro â€˜CHECK_CUDAâ€™\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:222:3: note: in expansion of macro â€˜CHECK_INPUTâ€™\n",
            "       CHECK_INPUT(gamma);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro â€˜C10_UNLIKELYâ€™\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro â€˜C10_UNLIKELY_OR_CONSTâ€™\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro â€˜TORCH_CHECK_WITHâ€™\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro â€˜TORCH_CHECKâ€™\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro â€˜CHECK_CUDAâ€™\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:223:3: note: in expansion of macro â€˜CHECK_INPUTâ€™\n",
            "       CHECK_INPUT(beta);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/layer_norm_cuda_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -maxrregcount=50 -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "    building 'mlp_cuda' extension\n",
            "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/mlp.cpp -o build/temp.linux-x86_64-3.6/csrc/mlp.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "    csrc/mlp.cpp: In function â€˜std::vector<at::Tensor> mlp_forward(int, int, std::vector<at::Tensor>)â€™:\n",
            "    csrc/mlp.cpp:56:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "       for (int i = 0; i < num_layers; i++) {\n",
            "                       ~~^~~~~~~~~~~~\n",
            "    csrc/mlp.cpp:64:77: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       auto out = at::empty({batch_size, output_features.back()}, inputs[0].type());\n",
            "                                                                                 ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    csrc/mlp.cpp:65:67: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       auto reserved_space = at::empty({reserved_size}, inputs[0].type());\n",
            "                                                                       ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    csrc/mlp.cpp:65:68: warning: narrowing conversion of â€˜reserved_sizeâ€™ from â€˜long unsigned intâ€™ to â€˜long intâ€™ inside { } [-Wnarrowing]\n",
            "       auto reserved_space = at::empty({reserved_size}, inputs[0].type());\n",
            "                                                                        ^\n",
            "    csrc/mlp.cpp:65:68: warning: narrowing conversion of â€˜reserved_sizeâ€™ from â€˜long unsigned intâ€™ to â€˜long intâ€™ inside { } [-Wnarrowing]\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:67:54: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "                                                          ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:129:28: note: in definition of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "         const auto& the_type = TYPE;                                             \\\n",
            "                                ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:131:56: warning: â€˜c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)â€™ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
            "         at::ScalarType _st = ::detail::scalar_type(the_type);                    \\\n",
            "                                                            ^\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:46:23: note: declared here\n",
            "     inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:76:10: warning: unused variable â€˜resultâ€™ [-Wunused-variable]\n",
            "         auto result = mlp_fp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:76:10: warning: unused variable â€˜resultâ€™ [-Wunused-variable]\n",
            "         auto result = mlp_fp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:76:10: warning: unused variable â€˜resultâ€™ [-Wunused-variable]\n",
            "         auto result = mlp_fp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp: In function â€˜std::vector<at::Tensor> mlp_backward(int, int, at::Tensor, std::vector<at::Tensor>, std::vector<at::Tensor>)â€™:\n",
            "    csrc/mlp.cpp:113:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "       for (int i = 0; i < num_layers; i++) {\n",
            "                       ~~^~~~~~~~~~~~\n",
            "    csrc/mlp.cpp:119:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "       for (int i = 0; i < inputs.size(); i++) {\n",
            "                       ~~^~~~~~~~~~~~~~~\n",
            "    csrc/mlp.cpp:120:67: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "         outputs.push_back(at::empty(inputs[i].sizes(), inputs[i].type()));  // clone for testing now\n",
            "                                                                       ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:123:54: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "                                                          ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:129:28: note: in definition of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "         const auto& the_type = TYPE;                                             \\\n",
            "                                ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:131:56: warning: â€˜c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)â€™ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
            "         at::ScalarType _st = ::detail::scalar_type(the_type);                    \\\n",
            "                                                            ^\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:46:23: note: declared here\n",
            "     inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < inputs.size(); i++) {\n",
            "                         ~~^~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:80: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                                                                    ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of â€˜(work_size / sizeof (scalar_t))â€™ from â€˜long unsigned intâ€™ to â€˜long intâ€™ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of â€˜(work_size / sizeof (scalar_t))â€™ from â€˜long unsigned intâ€™ to â€˜long intâ€™ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:139:10: warning: unused variable â€˜resultâ€™ [-Wunused-variable]\n",
            "         auto result = mlp_bp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < inputs.size(); i++) {\n",
            "                         ~~^~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:80: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                                                                    ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of â€˜(work_size / sizeof (scalar_t))â€™ from â€˜long unsigned intâ€™ to â€˜long intâ€™ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of â€˜(work_size / sizeof (scalar_t))â€™ from â€˜long unsigned intâ€™ to â€˜long intâ€™ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:139:10: warning: unused variable â€˜resultâ€™ [-Wunused-variable]\n",
            "         auto result = mlp_bp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < inputs.size(); i++) {\n",
            "                         ~~^~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:80: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                                                                    ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of â€˜(work_size / sizeof (scalar_t))â€™ from â€˜long unsigned intâ€™ to â€˜long intâ€™ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of â€˜(work_size / sizeof (scalar_t))â€™ from â€˜long unsigned intâ€™ to â€˜long intâ€™ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:139:10: warning: unused variable â€˜resultâ€™ [-Wunused-variable]\n",
            "         auto result = mlp_bp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/mlp_cuda.cu -o build/temp.linux-x86_64-3.6/csrc/mlp_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(14): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(18): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(23): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(100): warning: attribute \"__visibility__\" does not apply here\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(115): warning: attribute \"__visibility__\" does not apply here\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(14): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(18): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(23): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(100): warning: attribute \"__visibility__\" does not apply here\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(115): warning: attribute \"__visibility__\" does not apply here\n",
            "\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/mlp.o build/temp.linux-x86_64-3.6/csrc/mlp_cuda.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.6/mlp_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "    running install_lib\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n",
            "    copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n",
            "    copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/multi_tensor_apply.py -> /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/scaler.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/amp.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/_process_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/_amp_state.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/wrap.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/compat.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/frontend.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/utils.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/__version__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/rnn_compat.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/opt.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/functional_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/torch_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/tensor_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/handle.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/_initialize.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_adagrad.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_novograd.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/optimizers/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_lamb.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_sgd.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_adam.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
            "    copying build/lib.linux-x86_64-3.6/apex/reparameterization/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
            "    copying build/lib.linux-x86_64-3.6/apex/reparameterization/reparameterization.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
            "    copying build/lib.linux-x86_64-3.6/apex/reparameterization/weight_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
            "    copying build/lib.linux-x86_64-3.6/apex/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_adam.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_lamb.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_adam_v3.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_adam_v2.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_lamb.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fp16_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_sgd.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_adam.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/xentropy/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/xentropy/softmax_xentropy.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/sparsity/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/sparsity/sparse_masklib.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/sparsity/asp.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/groupbn/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/groupbn/batch_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/encdec_multihead_attn.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/self_multihead_attn.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/self_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/nvtx/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/nvtx/nvmarker.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/db.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/parse.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/__main__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/nvvp.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/index_slice_join_mutate.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/loss.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/randomSample.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/recurrentCell.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/prof.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/output.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/reduction.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/__main__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/data.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/normalization.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/linear.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/dropout.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/embedding.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/pointwise.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/base.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/misc.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/blas.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/convert.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/usage.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/softmax.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/optim.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/activation.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/utility.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/pooling.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/conv.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/normalization\n",
            "    copying build/lib.linux-x86_64-3.6/apex/normalization/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/normalization\n",
            "    copying build/lib.linux-x86_64-3.6/apex/normalization/fused_layer_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/normalization\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/mlp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/mlp/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/mlp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/mlp/mlp.py -> /usr/local/lib/python3.6/dist-packages/apex/mlp\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
            "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16util.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
            "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
            "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
            "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/loss_scaler.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm_kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm_kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/LARC.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/multiproc.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/distributed.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
            "    copying build/lib.linux-x86_64-3.6/apex/RNN/cells.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
            "    copying build/lib.linux-x86_64-3.6/apex/RNN/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
            "    copying build/lib.linux-x86_64-3.6/apex/RNN/models.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
            "    copying build/lib.linux-x86_64-3.6/apex/RNN/RNNBackend.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
            "    copying build/lib.linux-x86_64-3.6/mlp_cuda.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
            "    copying build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
            "    copying build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
            "    copying build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
            "    copying build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply/multi_tensor_apply.py to multi_tensor_apply.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/scaler.py to scaler.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/amp.py to amp.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_process_optimizer.py to _process_optimizer.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_amp_state.py to _amp_state.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/wrap.py to wrap.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/compat.py to compat.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/frontend.py to frontend.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/utils.py to utils.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/__version__.py to __version__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/rnn_compat.py to rnn_compat.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/opt.py to opt.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/functional_overrides.py to functional_overrides.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/torch_overrides.py to torch_overrides.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/tensor_overrides.py to tensor_overrides.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/handle.py to handle.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_initialize.py to _initialize.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_adagrad.py to fused_adagrad.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_novograd.py to fused_novograd.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_lamb.py to fused_lamb.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_sgd.py to fused_sgd.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_adam.py to fused_adam.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/reparameterization.py to reparameterization.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/weight_norm.py to weight_norm.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/distributed_fused_adam.py to distributed_fused_adam.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/distributed_fused_lamb.py to distributed_fused_lamb.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/distributed_fused_adam_v3.py to distributed_fused_adam_v3.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/distributed_fused_adam_v2.py to distributed_fused_adam_v2.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fused_lamb.py to fused_lamb.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fused_sgd.py to fused_sgd.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fused_adam.py to fused_adam.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy/softmax_xentropy.py to softmax_xentropy.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity/sparse_masklib.py to sparse_masklib.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity/asp.py to asp.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn/batch_norm.py to batch_norm.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/mask_softmax_dropout_func.py to mask_softmax_dropout_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py to fast_self_multihead_attn_norm_add_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py to fast_encdec_multihead_attn_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py to fast_encdec_multihead_attn_norm_add_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/encdec_multihead_attn.py to encdec_multihead_attn.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/self_multihead_attn.py to self_multihead_attn.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py to fast_self_multihead_attn_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/self_multihead_attn_func.py to self_multihead_attn_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/encdec_multihead_attn_func.py to encdec_multihead_attn_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx/nvmarker.py to nvmarker.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/db.py to db.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/parse.py to parse.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/__main__.py to __main__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/nvvp.py to nvvp.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/kernel.py to kernel.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/index_slice_join_mutate.py to index_slice_join_mutate.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/loss.py to loss.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/randomSample.py to randomSample.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/recurrentCell.py to recurrentCell.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/prof.py to prof.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/output.py to output.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/reduction.py to reduction.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/__main__.py to __main__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/data.py to data.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/normalization.py to normalization.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/linear.py to linear.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/dropout.py to dropout.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/embedding.py to embedding.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/pointwise.py to pointwise.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/base.py to base.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/misc.py to misc.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/blas.py to blas.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/convert.py to convert.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/usage.py to usage.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/softmax.py to softmax.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/optim.py to optim.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/activation.py to activation.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/utility.py to utility.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/pooling.py to pooling.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/conv.py to conv.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/normalization/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/normalization/fused_layer_norm.py to fused_layer_norm.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/mlp/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/mlp/mlp.py to mlp.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/fp16util.py to fp16util.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/loss_scaler.py to loss_scaler.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/sync_batchnorm_kernel.py to sync_batchnorm_kernel.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/optimized_sync_batchnorm_kernel.py to optimized_sync_batchnorm_kernel.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/sync_batchnorm.py to sync_batchnorm.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/LARC.py to LARC.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/multiproc.py to multiproc.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/optimized_sync_batchnorm.py to optimized_sync_batchnorm.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/distributed.py to distributed.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/cells.py to cells.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/models.py to models.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/RNNBackend.py to RNNBackend.cpython-36.pyc\n",
            "    running install_egg_info\n",
            "    running egg_info\n",
            "    creating apex.egg-info\n",
            "    writing apex.egg-info/PKG-INFO\n",
            "    writing dependency_links to apex.egg-info/dependency_links.txt\n",
            "    writing top-level names to apex.egg-info/top_level.txt\n",
            "    writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "    writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "    Copying apex.egg-info to /usr/local/lib/python3.6/dist-packages/apex-0.1-py3.6.egg-info\n",
            "    running install_scripts\n",
            "    writing list of installed files to '/tmp/pip-record-1quyzi5v/install-record.txt'\n",
            "    Running setup.py install for apex ... \u001b[?25l\u001b[?25hdone\n",
            "  Removing source in /tmp/pip-req-build-5ftpm7bw\n",
            "Successfully installed apex-0.1\n",
            "Cleaning up...\n",
            "Removed build tracker '/tmp/pip-req-tracker-h6cc4w5p'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oZeEME2xbWk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "bfb6f376-15c8-45cb-fd77-82f1837a59ba"
      },
      "source": [
        "!pip install pytorch_warmup"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch_warmup\n",
            "  Downloading https://files.pythonhosted.org/packages/7a/22/2fb600a06a1d1b493d54ac8fa6c41e96870985992fc504104e0620bc2ea4/pytorch_warmup-0.0.4-py3-none-any.whl\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_warmup) (1.5.1+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.1->pytorch_warmup) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.1->pytorch_warmup) (1.18.5)\n",
            "Installing collected packages: pytorch-warmup\n",
            "Successfully installed pytorch-warmup-0.0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnFPsZdvxvD0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import pytorch_warmup as warmup\n",
        "import os\n",
        "from progressbar import progressbar\n",
        "\n",
        "import apex"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKNgNEQGyAN0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
        "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
        "        self.fc1 = nn.Linear(4*4*50, 500)\n",
        "        self.fc2 = nn.Linear(500, 47)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = x.view(-1, 4*4*50)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgrcrd9myGSp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, device, train_loader, optimizer, lr_scheduler,\n",
        "          warmup_scheduler, epoch, history):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(progressbar(train_loader)):\n",
        "        lr = optimizer.param_groups[0]['lr']\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step(lr_scheduler.last_epoch+1)\n",
        "        warmup_scheduler.dampen()\n",
        "        if (batch_idx+1) % log_interval == 0:\n",
        "            loss = loss.item()\n",
        "            step = warmup_scheduler.last_step\n",
        "            history.write(f'{epoch},{step},{loss},{lr}\\n')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tL5QF6myKnH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(model, device, test_loader, epoch, evaluation):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in progressbar(test_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_acc = 100. * correct / len(test_loader.dataset)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset), test_acc))\n",
        "    evaluation.write(f'{epoch},{test_loss},{test_acc}\\n')\n",
        "    evaluation.flush()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOql7D5ryRVr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256,
          "referenced_widgets": [
            "bb35ce581bbc4101bb70e58e7c12232e",
            "47a1d76deaa74a019f8d1c81042ba9c8",
            "c9f52e23f2d549b18f85335629926c8c",
            "4d36030f440c4d729d5b0973d197d924",
            "50e86a6e8b0e43bc8585c360256fbfd1",
            "dfdb114eb4af4240b55babd2ad4707a9",
            "faf3241f622b466e951d58ba0c33419b",
            "b1a3268871cb4fc4901e41435b8f079c"
          ]
        },
        "outputId": "e9758086-64c1-4702-f90c-385218763613"
      },
      "source": [
        "torch.manual_seed(12345)\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True}\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "        datasets.EMNIST('.data', 'balanced', train=True, download=True,\n",
        "                        transform=transforms.Compose([\n",
        "                            transforms.ToTensor(),\n",
        "                            transforms.Normalize((0.1751,), (0.3332,))\n",
        "                        ])),\n",
        "        batch_size=64, shuffle=True, drop_last=True, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "        datasets.EMNIST('.data', 'balanced', train=False,\n",
        "                        transform=transforms.Compose([\n",
        "                            transforms.ToTensor(),\n",
        "                            transforms.Normalize((0.1751,), (0.3332,))\n",
        "                        ])),\n",
        "        batch_size=1000, shuffle=False, **kwargs)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading and extracting zip archive\n",
            "Downloading http://www.itl.nist.gov/iaui/vip/cs_links/EMNIST/gzip.zip to .data/EMNIST/raw/emnist.zip\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bb35ce581bbc4101bb70e58e7c12232e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting .data/EMNIST/raw/emnist.zip to .data/EMNIST/raw\n",
            "Processing byclass\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/pytorch/torch/csrc/utils/tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing bymerge\n",
            "Processing balanced\n",
            "Processing letters\n",
            "Processing digits\n",
            "Processing mnist\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhKBh5nYzoWH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "warmup_type = \"radam\"  # choices=['linear', 'exponential', 'radam', 'none']\n",
        "beta2 = 0.999\n",
        "wd = 0.01\n",
        "lr = 0.01\n",
        "lr_min = 3e-5\n",
        "epochs = 10\n",
        "log_interval = 10\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeKnCCxv1E1x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c1b3fd35-7e29-4604-b171-036131cb746d"
      },
      "source": [
        "output_dir = warmup_type\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "history = open(os.path.join(output_dir, 'history.csv'), 'w')\n",
        "history.write('epoch,step,loss,lr\\n')\n",
        "\n",
        "evaluation = open(os.path.join(output_dir, 'evaluation.csv'), 'w')\n",
        "evaluation.write('epoch,loss,accuracy\\n')\n",
        "\n",
        "model = Net().to(device)\n",
        "\n",
        "optimizer = apex.optimizers.FusedAdam(model.parameters(), lr=lr,\n",
        "                            betas=(0.9, beta2),\n",
        "                            weight_decay=wd)\n",
        "num_steps = len(train_loader) * epochs\n",
        "lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
        "        optimizer, T_max=num_steps, eta_min=lr_min)\n",
        "if warmup_type == 'linear':\n",
        "        warmup_scheduler = warmup.UntunedLinearWarmup(optimizer)\n",
        "elif warmup_type == 'exponential':\n",
        "        warmup_scheduler = warmup.UntunedExponentialWarmup(optimizer)\n",
        "elif warmup_type == 'radam':\n",
        "        warmup_scheduler = warmup.RAdamWarmup(optimizer)\n",
        "elif warmup_type == 'none':\n",
        "        warmup_scheduler = warmup.LinearWarmup(optimizer, 1)\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "        print(f\"Epoch: {epoch} of {epochs}\")\n",
        "        train(model, device, train_loader, optimizer, lr_scheduler,\n",
        "              warmup_scheduler, epoch, history)\n",
        "        test(model, device, test_loader, epoch, evaluation)\n",
        "\n",
        "history.close()\n",
        "evaluation.close()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 of 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "N/A% (0 of 1762) |                       | Elapsed Time: 0:00:00 ETA:  --:--:--/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "100% (1762 of 1762) |####################| Elapsed Time: 0:00:31 Time:  0:00:31\n",
            "100% (19 of 19) |########################| Elapsed Time: 0:00:03 Time:  0:00:03\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.5171, Accuracy: 15512/18800 (82.51%)\n",
            "\n",
            "Epoch: 2 of 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (1762 of 1762) |####################| Elapsed Time: 0:00:31 Time:  0:00:31\n",
            "100% (19 of 19) |########################| Elapsed Time: 0:00:03 Time:  0:00:03\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.5329, Accuracy: 15451/18800 (82.19%)\n",
            "\n",
            "Epoch: 3 of 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (1762 of 1762) |####################| Elapsed Time: 0:00:31 Time:  0:00:31\n",
            "100% (19 of 19) |########################| Elapsed Time: 0:00:03 Time:  0:00:03\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.4976, Accuracy: 15673/18800 (83.37%)\n",
            "\n",
            "Epoch: 4 of 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (1762 of 1762) |####################| Elapsed Time: 0:00:31 Time:  0:00:31\n",
            "100% (19 of 19) |########################| Elapsed Time: 0:00:03 Time:  0:00:03\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.4473, Accuracy: 16040/18800 (85.32%)\n",
            "\n",
            "Epoch: 5 of 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (1762 of 1762) |####################| Elapsed Time: 0:00:31 Time:  0:00:31\n",
            "100% (19 of 19) |########################| Elapsed Time: 0:00:03 Time:  0:00:03\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.4197, Accuracy: 16139/18800 (85.85%)\n",
            "\n",
            "Epoch: 6 of 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (1762 of 1762) |####################| Elapsed Time: 0:00:31 Time:  0:00:31\n",
            "100% (19 of 19) |########################| Elapsed Time: 0:00:03 Time:  0:00:03\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.4024, Accuracy: 16226/18800 (86.31%)\n",
            "\n",
            "Epoch: 7 of 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (1762 of 1762) |####################| Elapsed Time: 0:00:32 Time:  0:00:32\n",
            "100% (19 of 19) |########################| Elapsed Time: 0:00:03 Time:  0:00:03\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.3902, Accuracy: 16415/18800 (87.31%)\n",
            "\n",
            "Epoch: 8 of 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (1762 of 1762) |####################| Elapsed Time: 0:00:31 Time:  0:00:31\n",
            "100% (19 of 19) |########################| Elapsed Time: 0:00:03 Time:  0:00:03\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.4190, Accuracy: 16502/18800 (87.78%)\n",
            "\n",
            "Epoch: 9 of 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (1762 of 1762) |####################| Elapsed Time: 0:00:31 Time:  0:00:31\n",
            "100% (19 of 19) |########################| Elapsed Time: 0:00:03 Time:  0:00:03\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.4552, Accuracy: 16503/18800 (87.78%)\n",
            "\n",
            "Epoch: 10 of 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (1762 of 1762) |####################| Elapsed Time: 0:00:31 Time:  0:00:31\n",
            "100% (19 of 19) |########################| Elapsed Time: 0:00:03 Time:  0:00:03\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.4793, Accuracy: 16499/18800 (87.76%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qplBwWT3bjA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_hist = pd.read_csv(os.path.join(warmup_type, \"history.csv\"))\n",
        "df_eval = pd.read_csv(os.path.join(warmup_type, \"evaluation.csv\"))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOBvzvov32YZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "e7744421-2311-43a7-ba48-8af598bdc027"
      },
      "source": [
        "df_hist.plot(x=\"step\", y=\"lr\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f960334d668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1IC-BIU4BXO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "4a3b8884-f469-4325-9157-fbabcee931af"
      },
      "source": [
        "df_hist.plot(x=\"step\", y=\"loss\", ylim=(0,1))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f96033ae748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etb3dM5d4PpR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "89b542e2-0cb7-4d1e-b8f8-1ecd6e1be3af"
      },
      "source": [
        "df_eval.plot(x=\"epoch\", y=\"accuracy\", marker=\"o\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f96033aee48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}